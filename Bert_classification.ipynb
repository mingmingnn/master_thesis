{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b249fb7c",
   "metadata": {},
   "source": [
    "# BERT Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_excel('C:/Users/ming/Desktop/master project/Copy of Data_All_JAN_2024_Anonymized__For_Analysis_V1.2.xlsx', header=1)\n",
    "\n",
    "# Data Cleaning\n",
    "def clean_text(text):\n",
    "    text = str(text).lower().strip()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  \n",
    "    text = re.sub(r\"\\s+\", \" \", text)     \n",
    "    return text\n",
    "\n",
    "df['discomfort'] = df['Please describe the discomfort that you are experiencing'].fillna(\"\").apply(clean_text)\n",
    "df['cause'] = df['What do you believe is causing this discomfort?'].fillna(\"\").apply(clean_text)\n",
    "df['suggestion'] = df['What do you believe can be done to improve the wearing comfort for your hearing aids?'].fillna(\"\").apply(clean_text)\n",
    "\n",
    "# Filter invalid data\n",
    "invalid_responses = [\"no idea\", \"none\", \"not sure\", \"dont know\", \"dont now\", \"n/a\", \"unsure\", \"nothing\", \"?\", \"no\"]\n",
    "\n",
    "def is_valid(row):\n",
    "    if row['discomfort'] in invalid_responses and row['cause'] in invalid_responses:\n",
    "        return False\n",
    "    if len(row['discomfort']) < 2 and len(row['cause']) < 2:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df = df[df.apply(is_valid, axis=1)]\n",
    "\n",
    "# Merge discomfort and cause\n",
    "df['merged_input'] = df.apply(\n",
    "    lambda row: f\"Discomfort: {row['discomfort']}. Cause: {row['cause']}\", axis=1\n",
    ")\n",
    "\n",
    "# Valid Suggestion\n",
    "df['has_valid_suggestion'] = df['suggestion'].apply(lambda x: 0 if x in invalid_responses else 1)\n",
    "\n",
    "print(df[['merged_input', 'suggestion', 'has_valid_suggestion']].head())\n",
    "print(\"last_sample:\", len(df))\n",
    "\n",
    "\n",
    "df.to_csv(\"preprocessed_feedback.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import hdbscan\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "texts = df['merged_input'].tolist()\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(texts)\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10, metric='euclidean')\n",
    "cluster_labels = clusterer.fit_predict(embeddings)\n",
    "\n",
    "df['cluster'] = cluster_labels\n",
    "\n",
    "for c in set(cluster_labels):\n",
    "    cluster_texts = df[df['cluster'] == c]['merged_input'].tolist()\n",
    "    print(f\"\\nCluster {c}:\")\n",
    "    for t in cluster_texts[:10]: \n",
    "        print(f\"- {t}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final: 8 clusters\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"preprocessed_feedback.csv\")  \n",
    "texts = df['merged_input'].tolist()\n",
    "\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "\n",
    "n_clusters = 8\n",
    "print(f\"KMeans Cluster: {n_clusters}...\")\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(embeddings)\n",
    "\n",
    "\n",
    "score = silhouette_score(embeddings, df['cluster'])\n",
    "print(f\"Silhouette Score: {score:.4f}\")\n",
    "\n",
    "grouped = df.groupby('cluster')\n",
    "\n",
    "for cluster_id, group in grouped:\n",
    "    print(f\"\\n---- Cluster {cluster_id} ({len(group)} in total)\")\n",
    "    for text in group['merged_input'].head(20): \n",
    "        print(f\"- {text}\")\n",
    "    print(\"------------------\")\n",
    "\n",
    "\n",
    "df[['merged_input', 'cluster']].to_csv(\"kmeans_clustered_output.csv\", index=False)\n",
    "\n",
    "\n",
    "cluster_counts = df['cluster'].value_counts().sort_index()\n",
    "total_samples = len(df)\n",
    "\n",
    "cluster_stats = pd.DataFrame({\n",
    "    'Cluster': cluster_counts.index,\n",
    "    'Count': cluster_counts.values,\n",
    "    'Proportion (%)': (cluster_counts.values / total_samples * 100).round(2)\n",
    "})\n",
    "\n",
    "print(\"\\nCluster values and percentageï¼š\")\n",
    "print(cluster_stats)\n",
    "\n",
    "# save the table\n",
    "# cluster_stats.to_csv(\"cluster_statistics.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a7130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "score = silhouette_score(embeddings, df['cluster'])\n",
    "print(f\"\\nðŸ“ˆ Silhouette Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb2ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "scores = []\n",
    "ks = list(range(2, 15))  \n",
    "\n",
    "for k in ks:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "    score = silhouette_score(embeddings, labels)\n",
    "    scores.append(score)\n",
    "    print(f\"K={k}: Silhouette Score = {score:.4f}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(ks, scores, marker='o')\n",
    "plt.title('Silhouette Score for Different K')\n",
    "plt.xlabel('Number of clusters (K)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe67a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df = pd.read_csv(\"preprocessed_feedback.csv\")\n",
    "df['suggestion'] = df['suggestion'].fillna(\"\").str.lower()\n",
    "\n",
    "invalid_responses = [\"don't know\", \"none\", \"not sure\", \"nothing\", \"n/a\", \"no\"]\n",
    "\n",
    "def label_suggestion(text):\n",
    "    if \"smaller dome\" in text or \"7mm\" in text:\n",
    "        return \"Smaller Dome\"\n",
    "    elif \"custom earpiece\" in text or \"custom\" in text:\n",
    "        return \"Custom Earpiece\"\n",
    "    elif \"material\" in text or \"comfortable earpiece\" in text or \"better earpiece\" in text:\n",
    "        return \"Better Material\"\n",
    "    elif \"vent\" in text or \"air circulation\" in text:\n",
    "        return \"Improve Ventilation\"\n",
    "    elif text == \"\" or text in invalid_responses:\n",
    "        return \"No Suggestion\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df['suggestion_label'] = df['suggestion'].apply(label_suggestion)\n",
    "other_df = df[df['suggestion_label'] == \"Other\"]\n",
    "\n",
    "custom_stopwords = [\n",
    "    \"know\", \"just\", \"think\", \"really\", \"maybe\", \"sure\", \"need\", \"donâ€™t\", \"don\", \"make\", \"get\", \n",
    "    \"would\", \"could\", \"wear\", \"wearing\", \"aid\", \"aids\", \"hearing\", \"time\", \"use\", \"ear\", \"ears\", \n",
    "    \"fit\", \"like\", \"feel\", \"piece\", \"help\", \"one\", \"two\", \"see\", \"thing\", \"good\", \"better\"\n",
    "]\n",
    "\n",
    "custom_stopwords += [\n",
    "    \"in\", \"on\", \"at\", \"for\", \"with\", \"by\", \"to\", \"from\", \"into\", \"onto\", \"about\", \"around\", \"near\",\n",
    "    \"in the\", \"on the\", \"at the\", \"for me\", \"with my\", \"to my\", \"by the\", \"from the\", \"in my\", \"on my\", \"and\", \"are\", \"as\",\n",
    "    \"be\", \"but\", \"can\", \"dont\", \"Donat\", \"have\", \"it\", \"is\", \"if\", \"more\", \"much\", \"so\", \"this\", \"that\", \"they\", \"them\", \"the\",\n",
    "    \"not\", \"my\", \"of\", \"mine\", \"donÃ¢t\", \"nothing\", \"no\", \"out\", \"or\", \"idea\", \"when\", \"me\", \"very\", \"am\", \"do\", \"all\", \"an\", \"im\",\n",
    "    \"too\", \"you\", \"will\", \"was\", \"there\", \"were\", \" \", \"anything\", \"comfort\", \"comfortable\", \"different\", \"discomfort\", \"fine\", \"had\", \n",
    "    \"sometimes\"\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=custom_stopwords, max_features=30)\n",
    "X = vectorizer.fit_transform(other_df['suggestion'].dropna())\n",
    "\n",
    "word_counts = X.toarray().sum(axis=0)\n",
    "keywords = vectorizer.get_feature_names_out()\n",
    "word_freq = dict(zip(keywords, word_counts))\n",
    "\n",
    "# Top10\n",
    "print(\"\\n Filtered Top10 Keywordsï¼š\")\n",
    "for word, freq in sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "sorted_word_freq = dict(sorted(word_freq.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(sorted_word_freq.keys(), sorted_word_freq.values())\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top Keywords in 'Other' Suggestions (Cleaned)\")\n",
    "plt.show()\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate_from_frequencies(word_freq)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"WordCloud of 'Other' Suggestions (Cleaned)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92105ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# Data\n",
    "df = pd.read_csv(\"preprocessed_feedback.csv\")\n",
    "texts = df['merged_input'].tolist()\n",
    "\n",
    "# BERT \n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "# KMeans\n",
    "n_clusters = 8\n",
    "print(f\"KMeans Cluster: {n_clusters}...\")\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# UMAP -> 2D\n",
    "umap_reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, metric='cosine', random_state=42)\n",
    "umap_embeddings = umap_reducer.fit_transform(embeddings)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for cluster_id in range(n_clusters):\n",
    "    indices = df['cluster'] == cluster_id\n",
    "    plt.scatter(\n",
    "        umap_embeddings[indices, 0],\n",
    "        umap_embeddings[indices, 1],\n",
    "        label=f'Cluster {cluster_id}',\n",
    "        alpha=0.6\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"KMeans + UMAP clustering visualization\")\n",
    "plt.xlabel(\"UMAP-1\")\n",
    "plt.ylabel(\"UMAP-2\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63322cf",
   "metadata": {},
   "source": [
    "## TF/IDF create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import pipeline\n",
    "from collections import defaultdict\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/ming/Desktop/master project/kmeans_clustered_output.csv\")  \n",
    "\n",
    "# 'google/flan-t5-base' \n",
    "summarizer = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", max_length=15)\n",
    "\n",
    "clustered_texts = df.groupby('cluster')['merged_input'].apply(list)\n",
    "\n",
    "cluster_labels = {}\n",
    "\n",
    "for cluster_id, texts in clustered_texts.items():\n",
    "    print(f\"\\nProcessing Cluster {cluster_id}\")\n",
    "\n",
    "    # Abstract key wordsï¼ˆTF-IDFï¼‰\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5)\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    top_words = vectorizer.get_feature_names_out()\n",
    "    keyword_summary = \", \".join(top_words)\n",
    "\n",
    "    print(f\"Top keywords (TF-IDF): {keyword_summary}\")\n",
    "\n",
    "    # 2. generated_label\n",
    "    top_samples = texts[:20]\n",
    "    prompt = \"Generate a short label for the following user complaints:\\n\" + \"\\n\".join(top_samples)\n",
    "\n",
    "    try:\n",
    "        label = summarizer(prompt)[0]['generated_text']\n",
    "    except Exception as e:\n",
    "        label = \"Label Generation Failed\"\n",
    "\n",
    "    cluster_labels[cluster_id] = {\n",
    "        \"tfidf_keywords\": keyword_summary,\n",
    "        \"generated_label\": label\n",
    "    }\n",
    "\n",
    "print(\"\\n Final Cluster Labels \")\n",
    "for cid, content in cluster_labels.items():\n",
    "    print(f\"Cluster {cid}:\")\n",
    "    print(f\"  TF-IDF keywords: {content['tfidf_keywords']}\")\n",
    "    print(f\"  Generated label: {content['generated_label']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7185931",
   "metadata": {},
   "source": [
    "## Supervised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3009eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cluster_names = [\n",
    "    \"Interfere with Glasses\",\n",
    "    \"No Discomfort\",\n",
    "    \"Stability Issue and Wearing Scenario Discomfort\",\n",
    "    \"General Itching (Unspecified Itching Cause)\",\n",
    "    \"Severe Itching and Foreign Body Sensation\",\n",
    "    \"Dome-Wire Irritation\",\n",
    "    \"Improper Fit (Ear Canal Pressure)\",\n",
    "    \"Dome Size Issue\"\n",
    "]\n",
    "\n",
    "cluster_counts = [1281, 1270, 2561, 2221, 1553, 1831, 2833, 655]\n",
    "\n",
    "sorted_pairs = sorted(zip(cluster_counts, cluster_names), reverse=True)\n",
    "sorted_counts, sorted_names = zip(*sorted_pairs)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "bars = plt.bar(sorted_names, sorted_counts, color=\"royalblue\")\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, height + 30, f\"{height}\", ha='center', fontsize=10)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel(\"Number of Responses\")\n",
    "plt.title(\"Cluster Distribution After Human-Aided Labeling \")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635833ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"kmeans_clustered_output.csv\")\n",
    "\n",
    "cluster_to_label = {\n",
    "    0: \"Interfere with Glasses\",\n",
    "    1: \"No Discomfort\",\n",
    "    2: \"Stability Issue and Wearing Scenario Discomfort\",\n",
    "    3: \"General Itching (Unspecified Itching Cause)\",\n",
    "    4: \"Severe Itching and Foreign Body Sensation\",\n",
    "    5: \"Dome-Wire Irritation\",\n",
    "    6: \"Improper Fit (Ear Canal Pressure)\",\n",
    "    7: \"Dome Size Issue\"\n",
    "}\n",
    "\n",
    "df['normalized_label'] = df['cluster'].map(cluster_to_label)\n",
    "\n",
    "\n",
    "df_ready = df[['merged_input', 'normalized_label']]\n",
    "df_ready.to_csv(\"training_data_labeled.csv\", index=False)\n",
    "\n",
    "print(\"training_data_labeled.csv saved\")\n",
    "print(df_ready.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151d8bcc",
   "metadata": {},
   "source": [
    "# Discomfort Reason Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb285ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Fine-tuning (Final Version)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "from datasets import Dataset\n",
    "\n",
    "df = pd.read_csv(\"kmeans_clustered_output.csv\")\n",
    "\n",
    "cluster_to_label = {\n",
    "    0: \"Interfere with Glasses\",\n",
    "    1: \"No Discomfort\",\n",
    "    2: \"Stability Issue and Wearing Scenario Discomfort\",\n",
    "    3: \"General Itching (Unspecified Itching Cause)\",\n",
    "    4: \"Severe Itching and Foreign Body Sensation\",\n",
    "    5: \"Dome-Wire Irritation\",\n",
    "    6: \"Improper Fit (Ear Canal Pressure)\",\n",
    "    7: \"Dome Size Issue\"\n",
    "}\n",
    "df['label'] = df['cluster'].map(cluster_to_label)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label_id'] = le.fit_transform(df['label'])\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label_id'])\n",
    "print(f\"train_dataset: {len(train_df)}ï¼Œtest_dataset: {len(test_df)}\")\n",
    "\n",
    "\n",
    "TARGET_COUNT = 2000  \n",
    "balanced_train_dfs = []\n",
    "\n",
    "for label, group in train_df.groupby('label'):\n",
    "    if len(group) < TARGET_COUNT:\n",
    "        sampled_group = group.sample(TARGET_COUNT, replace=True, random_state=42)\n",
    "    else:\n",
    "        sampled_group = group.sample(TARGET_COUNT, replace=False, random_state=42)\n",
    "    balanced_train_dfs.append(sampled_group)\n",
    "\n",
    "balanced_train_df = pd.concat(balanced_train_dfs).reset_index(drop=True)\n",
    "print(f\"Balanced_train_sample: {len(balanced_train_df)}\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokens = tokenizer(examples[\"merged_input\"], padding=\"max_length\", truncation=True, max_length=64)  \n",
    "    tokens[\"labels\"] = examples[\"label_id\"]\n",
    "    return tokens\n",
    "\n",
    "train_dataset = Dataset.from_pandas(balanced_train_df[['merged_input', 'label_id']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['merged_input', 'label_id']])\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Load Bert Model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(le.classes_))\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_feedback_temp\",  \n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,   \n",
    "    per_device_eval_batch_size=16,    \n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"no\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    dataloader_num_workers=0,\n",
    "    report_to=\"none\",\n",
    "    fp16=False, \n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# -Evaluation\n",
    "metrics = trainer.evaluate()\n",
    "print(\"test_dataset: \")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# Confusion Matrix on Validation Set\n",
    "preds = trainer.predict(tokenized_test)\n",
    "y_true = preds.label_ids\n",
    "y_pred = preds.predictions.argmax(-1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix on Validation Set\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c013a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "predictions = trainer.predict(tokenized_datasets['test'])\n",
    "\n",
    "logits = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "\n",
    "print(\"\\n Classification Report \")\n",
    "print(classification_report(labels, preds, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2fb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and Tokenizer\n",
    "SAVE_DIR = \"./bert_feedback_final_model\"\n",
    "\n",
    "trainer.save_model(SAVE_DIR)\n",
    "tokenizer.save_pretrained(SAVE_DIR)\n",
    "\n",
    "print(f\"Model saved to {SAVE_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "model_path = \"./bert_feedback_final_model\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "class_names = [\n",
    "    'Dome Size Issue',\n",
    "    'Dome-Wire Irritation',\n",
    "    'General Itching (Unspecified Itching Cause)',\n",
    "    'Improper Fit (Ear Canal Pressure)',\n",
    "    'Interfere with Glasses',\n",
    "    'No Discomfort',\n",
    "    'Severe Itching and Foreign Body Sensation',\n",
    "    'Stability Issue and Wearing Scenario Discomfort'\n",
    "]\n",
    "\n",
    "def predict_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=64)\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.softmax(outputs.logits, dim=-1).detach().cpu().numpy()[0]\n",
    "    \n",
    "    top3_idx = np.argsort(probs)[-3:][::-1]\n",
    "    \n",
    "    print(f\"\\n Input Text: {text}\")\n",
    "    for i in range(3):\n",
    "        print(f\"Predict Top {i+1}: {class_names[top3_idx[i]]} ( {probs[top3_idx[i]]*100:.2f}%)\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Random sample sentences for test\n",
    "if __name__ == \"__main__\":\n",
    "    examples = [\n",
    "        \"After wearing for a few hours, my ear starts to itch badly.\",\n",
    "        \"The dome feels too big and causes discomfort.\",\n",
    "        \"I have no discomfort at all, wearing experience is great.\",\n",
    "        \"When wearing glasses, the hearing aid gets pushed and feels weird.\",\n",
    "        \"The dome easily falls out when I am walking fast.\",\n",
    "        \"There is constant irritation where the wire touches my skin.\",\n",
    "        \"Wearing the hearing aid while exercising feels unstable.\",\n",
    "        \"Slight itching happens after prolonged wear, but acceptable.\"\n",
    "    ]\n",
    "    \n",
    "    for text in examples:\n",
    "        predict_text(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93971f59",
   "metadata": {},
   "source": [
    "# Suggestion Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb869652",
   "metadata": {},
   "outputs": [],
   "source": [
    "## updated version\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"preprocessed_feedback.csv\")\n",
    "df['suggestion'] = df['suggestion'].fillna(\"\").str.lower()\n",
    "invalid_responses = [\"don't know\", \"none\", \"not sure\", \"nothing\", \"n/a\", \"no\"]\n",
    "df['valid'] = df['suggestion'].apply(lambda x: 0 if any(stop in x for stop in invalid_responses) else 1)\n",
    "\n",
    "\n",
    "def label_suggestion(text):\n",
    "    if \"smaller dome\" in text or \"7mm\" in text:\n",
    "        return \"Smaller Dome\"\n",
    "    elif \"custom earpiece\" in text or \"custom\" in text:\n",
    "        return \"Custom Earpiece\"\n",
    "    elif \"material\" in text or \"comfortable earpiece\" in text or \"better earpiece\" in text:\n",
    "        return \"Better Material\"\n",
    "    elif \"vent\" in text or \"air circulation\" in text:\n",
    "        return \"Improve Ventilation\"\n",
    "    elif text == \"\" or text in invalid_responses:\n",
    "        return \"No Suggestion\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df['suggestion_label'] = df['suggestion'].apply(label_suggestion)\n",
    "df_valid = df[df['valid'] == 1].copy()\n",
    "df_valid = df_valid[df_valid['suggestion'].str.split().apply(len) >= 3]\n",
    "\n",
    "TARGET_COUNT = 200\n",
    "df_balanced = []\n",
    "\n",
    "for label, group in df_valid.groupby('suggestion_label'):\n",
    "    if label == \"Other\":\n",
    "        sampled = group.sample(n=1000, random_state=42) if len(group) > 1000 else group\n",
    "    else:\n",
    "        sampled = group.sample(n=TARGET_COUNT, replace=True, random_state=42) if len(group) < TARGET_COUNT else group.sample(n=TARGET_COUNT, replace=False, random_state=42)\n",
    "    df_balanced.append(sampled)\n",
    "\n",
    "df_final = pd.concat(df_balanced).reset_index(drop=True)\n",
    "\n",
    "print(\"Balanced Distributionï¼š\")\n",
    "print(df_final['suggestion_label'].value_counts())\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_final['label_id'] = le.fit_transform(df_final['suggestion_label'])\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df_final, test_size=0.1, stratify=df_final['label_id'], random_state=42\n",
    ")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokens = tokenizer(examples[\"suggestion\"], padding=\"max_length\", truncation=True, max_length=64)\n",
    "    tokens[\"labels\"] = examples[\"label_id\"]\n",
    "    return tokens\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[['suggestion', 'label_id']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['suggestion', 'label_id']])\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(le.classes_))\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_suggestion_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"./bert_suggestion_model\")\n",
    "tokenizer.save_pretrained(\"./bert_suggestion_model\")\n",
    "\n",
    "print(\"Model saved to ./bert_suggestion_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c450b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load model & tokenizer\n",
    "model_path = \"./bert_suggestion_model\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "class_names = [\n",
    "    \"Better Material\",\n",
    "    \"Custom Earpiece\",\n",
    "    \"Improve Ventilation\",\n",
    "    \"Other\",\n",
    "    \"Smaller Dome\"\n",
    "]\n",
    "\n",
    "def predict_suggestion(text):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=-1).squeeze().cpu().numpy()\n",
    "    \n",
    "    top3 = np.argsort(probs)[-3:][::-1]\n",
    "    print(f\"\\nInput Suggestionï¼š{text}\")\n",
    "    for i in range(3):\n",
    "        print(f\"Presicted Top {i+1}: {class_names[top3[i]]} ( {probs[top3[i]]*100:.2f}%)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    examples = [\n",
    "        \"Use a softer dome or better material.\",\n",
    "        \"I wish the dome was smaller.\",\n",
    "        \"Consider adding more vents.\",\n",
    "        \"Custom fit earpiece would be more comfortable.\",\n",
    "        \"It's okay, no issues really.\"\n",
    "    ]\n",
    "    for text in examples:\n",
    "        predict_suggestion(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094256b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "preds = trainer.predict(tokenized_test)\n",
    "y_true = preds.label_ids\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "class_names = [\n",
    "    \"Better Material\",\n",
    "    \"Custom Earpiece\",\n",
    "    \"Improve Ventilation\",\n",
    "    \"Other\",\n",
    "    \"Smaller Dome\"\n",
    "]\n",
    "\n",
    "# classification report\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, digits=4)\n",
    "print(\"\\n classification reportï¼š\")\n",
    "print(report)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
    "plt.title(\"Suggestion Classifier - Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d96190",
   "metadata": {},
   "source": [
    "# Sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeceb7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-label TF-IDF+K-MEANS\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"preprocessed_feedback.csv\")\n",
    "df['suggestion'] = df['suggestion'].fillna(\"\").str.lower()\n",
    "\n",
    "invalid_responses = [\"don't know\", \"none\", \"not sure\", \"nothing\", \"n/a\", \"no\"]\n",
    "df['valid'] = df['suggestion'].apply(lambda x: 0 if any(stop in x for stop in invalid_responses) else 1)\n",
    "df_valid = df[df['valid'] == 1]\n",
    "df_valid = df_valid[df_valid['suggestion'].str.split().apply(len) >= 3].reset_index(drop=True)\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(df_valid['suggestion'])\n",
    "\n",
    "# KMeans suggestion texts\n",
    "n_clusters = 8  \n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df_valid['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "X_2d = tsne.fit_transform(X.toarray())\n",
    "df_valid['x'] = X_2d[:, 0]\n",
    "df_valid['y'] = X_2d[:, 1]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=df_valid, x=\"x\", y=\"y\", hue=\"cluster\", palette=\"tab10\")\n",
    "plt.title(\"Suggestion Clustering (TF-IDF + KMeans + TSNE)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for c in sorted(df_valid['cluster'].unique()):\n",
    "    print(f\"\\n Cluster {c} Suggestion Exampleï¼š\")\n",
    "    print(df_valid[df_valid['cluster'] == c]['suggestion'].head(5).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62617934",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_label = {\n",
    "    0: \"Smaller Dome\",\n",
    "    1: \"Better Dome Material\",\n",
    "    2: \"Custom Fit / Wire Design\",\n",
    "    3: \"No Suggestion / Neutral\",\n",
    "    4: \"General / Other\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b328a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train BERT Classifier based on clustered labels\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"preprocessed_feedback.csv\")\n",
    "df['suggestion'] = df['suggestion'].fillna(\"\").str.lower()\n",
    "invalid_responses = [\"don't know\", \"none\", \"not sure\", \"nothing\", \"n/a\", \"no\"]\n",
    "df['valid'] = df['suggestion'].apply(lambda x: 0 if any(stop in x for stop in invalid_responses) else 1)\n",
    "df_valid = df[df['valid'] == 1].copy()\n",
    "df_valid = df_valid[df_valid['suggestion'].str.split().apply(len) >= 3].reset_index(drop=True)\n",
    "\n",
    "# Cluster_to_label\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(df_valid['suggestion'])\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df_valid['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "cluster_to_label = {\n",
    "    0: \"Smaller Dome\",\n",
    "    1: \"Better Dome Material\",\n",
    "    2: \"Custom Fit / Wire Design\",\n",
    "    3: \"No Suggestion / Neutral\",\n",
    "    4: \"General / Other\"\n",
    "}\n",
    "df_valid['suggestion_label'] = df_valid['cluster'].map(cluster_to_label)\n",
    "\n",
    "# Label Encoder\n",
    "le = LabelEncoder()\n",
    "df_valid['label_id'] = le.fit_transform(df_valid['suggestion_label'])\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df_valid, test_size=0.1, stratify=df_valid['label_id'], random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokens = tokenizer(examples[\"suggestion\"], padding=\"max_length\", truncation=True, max_length=64)\n",
    "    tokens[\"labels\"] = examples[\"label_id\"]\n",
    "    return tokens\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[['suggestion', 'label_id']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['suggestion', 'label_id']])\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(le.classes_))\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_suggestion_final_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"./bert_suggestion_final_model\")\n",
    "tokenizer.save_pretrained(\"./bert_suggestion_final_model\")\n",
    "\n",
    "print(\"Final suggestion classifier Model saved to ./bert_suggestion_final_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6759cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_path = \"./bert_suggestion_final_model\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "label_names = [\n",
    "    \"Better Dome Material\",\n",
    "    \"Custom Fit / Wire Design\",\n",
    "    \"General / Other\",\n",
    "    \"No Suggestion / Neutral\",\n",
    "    \"Smaller Dome\"\n",
    "]\n",
    "\n",
    "def predict_suggestion(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=64)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=-1).squeeze().numpy()\n",
    "    top3 = np.argsort(probs)[::-1][:3]\n",
    "\n",
    "    print(f\"\\nInput suggestionï¼š{text}\")\n",
    "    for i, idx in enumerate(top3):\n",
    "        print(f\"Top {i+1}: {label_names[idx]} ï¼ˆ {probs[idx]*100:.2f}ï¼…ï¼‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22168310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "predict_suggestion(\"make the dome smaller\")\n",
    "predict_suggestion(\"I would like a custom fit\")\n",
    "predict_suggestion(\"It's already perfect\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e3bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "preds = trainer.predict(tokenized_test)\n",
    "y_true = preds.label_ids\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "label_names = list(le.classes_)\n",
    "\n",
    "print(\"\\n Classification Reportï¼š\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_names, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
    "plt.title(\"Suggestion Classifier - Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a60d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"preprocessed_feedback.csv\")\n",
    "\n",
    "#  rule-based for sentiment\n",
    "def label_sentiment(text):\n",
    "    text = text.lower()\n",
    "    if any(word in text for word in [\"no discomfort\", \"none\", \"satisfied\", \"very little discomfort\"]):\n",
    "        return \"Satisfied\"\n",
    "    elif any(word in text for word in [\"minor\", \"slightly uncomfortable\", \"not bad\", \"awkward\"]):\n",
    "        return \"Neutral\"\n",
    "    elif any(word in text for word in [\"hurts\", \"itching\", \"pressure\", \"pain\", \"tightness\", \"irritation\"]):\n",
    "        return \"Dissatisfied\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df['sentiment_label'] = df['merged_input'].apply(label_sentiment)\n",
    "\n",
    "# label encode\n",
    "le_sentiment = LabelEncoder()\n",
    "df['sentiment_id'] = le_sentiment.fit_transform(df['sentiment_label'])\n",
    "\n",
    "# Tokenize\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_sentiment(examples):\n",
    "    tokens = tokenizer(examples[\"merged_input\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    tokens[\"labels\"] = examples[\"sentiment_id\"]\n",
    "    return tokens\n",
    "\n",
    "dataset = Dataset.from_pandas(df[['merged_input', 'sentiment_id']])\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "tokenized_datasets = dataset.map(tokenize_sentiment, batched=True)\n",
    "\n",
    "# BERT sentiment model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(le_sentiment.classes_))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_sentiment_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    dataloader_num_workers=0\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"./bert_sentiment_model\")\n",
    "tokenizer.save_pretrained(\"./bert_sentiment_model\")\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f05ccb9",
   "metadata": {},
   "source": [
    "# Final Model: demographic + sentiment + discomfort + image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model_sentiment = BertForSequenceClassification.from_pretrained(\n",
    "    \"./bert_sentiment_model\", num_labels=3  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dda133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "df = pd.read_csv(\"preprocessed_feedback.csv\")\n",
    "df['merged_input'] = df['merged_input'].fillna(\"\").astype(str)\n",
    "df['suggestion'] = df['suggestion'].fillna(\"\").astype(str)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Sentient/Satisfaction prediction model\n",
    "sentiment_classes = [\"Dissatisfied\", \"Neutral\", \"Satisfied\"]\n",
    "model_sentiment = BertForSequenceClassification.from_pretrained(\"./bert_sentiment_model\", num_labels=3).to(device)\n",
    "tokenizer_sentiment = BertTokenizer.from_pretrained(\"./bert_sentiment_model\")\n",
    "model_sentiment.eval()\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer_sentiment(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model_sentiment(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1).squeeze().cpu().numpy()\n",
    "    return sentiment_classes[int(np.argmax(probs))]\n",
    "\n",
    "df['sentiment_label'] = df['merged_input'].apply(predict_sentiment)\n",
    "\n",
    "# Discomfort Reason Prediction Model\n",
    "reason_classes = [\n",
    "    'Dome Size Issue',\n",
    "    'Dome-Wire Irritation',\n",
    "    'General Itching (Unspecified Itching Cause)',\n",
    "    'Improper Fit (Ear Canal Pressure)',\n",
    "    'Interfere with Glasses',\n",
    "    'No Discomfort',\n",
    "    'Severe Itching and Foreign Body Sensation',\n",
    "    'Stability Issue and Wearing Scenario Discomfort'\n",
    "]\n",
    "model_reason = BertForSequenceClassification.from_pretrained(\"./bert_feedback_final_model\", num_labels=len(reason_classes)).to(device)\n",
    "tokenizer_reason = BertTokenizer.from_pretrained(\"./bert_feedback_final_model\")\n",
    "model_reason.eval()\n",
    "\n",
    "def predict_reason(text):\n",
    "    inputs = tokenizer_reason(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model_reason(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1).squeeze().cpu().numpy()\n",
    "    return reason_classes[int(np.argmax(probs))]\n",
    "\n",
    "df['normalized_label'] = df['merged_input'].apply(predict_reason)\n",
    "\n",
    "# Suggestion Classfication Prediction Model\n",
    "suggestion_classes = [\"Smaller Dome\", \"Better Dome Material\", \"Custom Fit / Wire Design\", \"No Suggestion / Neutral\", \"General / Other\"]\n",
    "model_suggestion = BertForSequenceClassification.from_pretrained(\"./bert_suggestion_final_model\", num_labels=len(suggestion_classes)).to(device)\n",
    "tokenizer_suggestion = BertTokenizer.from_pretrained(\"./bert_suggestion_final_model\")\n",
    "model_suggestion.eval()\n",
    "\n",
    "def predict_suggestion(text):\n",
    "    inputs = tokenizer_suggestion(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=64)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model_suggestion(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1).squeeze().cpu().numpy()\n",
    "    return suggestion_classes[int(np.argmax(probs))]\n",
    "\n",
    "df['suggestion_label'] = df['suggestion'].apply(predict_suggestion)\n",
    "\n",
    "\n",
    "df.to_csv(\"dashboard_ready_data.csv\", index=False)\n",
    "print(\"Predicted saved to dashboard_ready_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Processing\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Read Data\n",
    "df = pd.read_csv(\"preprocessed_feedback.csv\")\n",
    "\n",
    "# Coordinate Cleaning\n",
    "df['X-coordinate'] = pd.to_numeric(df['X-coordinate'], errors='coerce')\n",
    "df['Y-coordinate'] = pd.to_numeric(df['Y-coordinate'], errors='coerce')\n",
    "\n",
    "df_coords = df.dropna(subset=['X-coordinate', 'Y-coordinate'])\n",
    "df_coords = df_coords[\n",
    "    (df_coords['X-coordinate'] >= 0) & (df_coords['X-coordinate'] <= 100) &\n",
    "    (df_coords['Y-coordinate'] >= -100) & (df_coords['Y-coordinate'] <= 100)\n",
    "].copy()\n",
    "\n",
    "# Clusters\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "df_coords['zone_cluster'] = kmeans.fit_predict(df_coords[['X-coordinate', 'Y-coordinate']])\n",
    "\n",
    "df['zone_cluster'] = -1\n",
    "df.loc[df_coords.index, 'zone_cluster'] = df_coords['zone_cluster'].astype(int)\n",
    "\n",
    "# One-hot Encoded\n",
    "zone_dummies = pd.get_dummies(df['zone_cluster'], prefix=\"zone\")\n",
    "df = pd.concat([df[['merged_input', 'X-coordinate', 'Y-coordinate', 'zone_cluster']], zone_dummies], axis=1)\n",
    "\n",
    "\n",
    "df.to_csv(\"image_features_ready.csv\", index=False)\n",
    "print(\"Saved to image_features_ready.csv\")\n",
    "\n",
    "# Only include coordinate + zone_cluster + zone one-hotï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f245b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# main data\n",
    "df_main = pd.read_csv(\"preprocessed_feedback.csv\")\n",
    "\n",
    "# Sentiment + reason + suggestion\n",
    "df_text = pd.read_csv(\"dashboard_ready_data.csv\")\n",
    "df_main = df_main.merge(\n",
    "    df_text[[\"merged_input\", \"sentiment_label\", \"normalized_label\", \"suggestion_label\"]],\n",
    "    on=\"merged_input\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Image_feature \n",
    "df_image = pd.read_csv(\"image_features_ready.csv\")\n",
    "\n",
    "# Coordinate, region one-hot, zone cluster one-hot\n",
    "image_feature_cols = [\n",
    "    \"merged_input\", \"X-coordinate\", \"Y-coordinate\", \"zone_cluster\"\n",
    "] + [col for col in df_image.columns if col.startswith(\"zone_\")]\n",
    "\n",
    "df_main = df_main.merge(df_image[image_feature_cols], on=\"merged_input\", how=\"left\")\n",
    "\n",
    "df_main = df_main.drop(columns=[\"Ear region marked\", \"has_region\", \n",
    "                                \"region_inner_ear\", \"region_behind_the_ear\", \"region_upper_front_part_of_ear\"],\n",
    "                       errors=\"ignore\")\n",
    "\n",
    "df_main.to_csv(\"final_model_dataset.csv\", index=False)\n",
    "print(\"final_model_dataset.csv saved (includes structured + text + simplified image features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf276e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "print(df_coords[\"X-coordinate\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df_clean = df_coords[\n",
    "    (df_coords[\"X-coordinate\"] >= 0) & (df_coords[\"X-coordinate\"] <= 100) &\n",
    "    (df_coords[\"Y-coordinate\"] >= -100) & (df_coords[\"Y-coordinate\"] <= 100)\n",
    "].copy()\n",
    "\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "df_clean[\"zone_cluster\"] = kmeans.fit_predict(df_clean[[\"X-coordinate\", \"Y-coordinate\"]])\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "for cluster in range(6):\n",
    "    subset = df_clean[df_clean[\"zone_cluster\"] == cluster]\n",
    "    plt.scatter(subset[\"X-coordinate\"], subset[\"Y-coordinate\"], label=f\"Cluster {cluster}\", alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Coordinate Clusters\")\n",
    "plt.legend(loc='upper right') \n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e738cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full workflow - One-hot encoded + Standarized + MLP Training\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"final_model_dataset.csv\")\n",
    "drop_cols = [col for col in df.columns if any(keyword in col for keyword in [\n",
    "    \"Respondent ID\", \"Collector ID\", \"Survey Collector\", \"comparison INDEX\", \"Comfort Deviation\",\n",
    "    \"Plot\", \"Start Date\", \"End Date\", \"Language\"\n",
    "])]\n",
    "df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "selected_columns = [\n",
    "    # structured data\n",
    "    \"Style\", \"Platform\", \"Earpiece Configuration\", \"What is your gender?\",\n",
    "    \"What is your current age?\", \"How long have you been using hearing aids?\",\n",
    "\n",
    "    # label\n",
    "    \"sentiment_label\", \"normalized_label\",\n",
    "\n",
    "    # image region\n",
    "    \"zone_cluster\", \n",
    "    # \"has_region\", \"region_inner_ear\", \"region_behind_the_ear\", \"region_upper_front_part_of_ear\",  \n",
    "\n",
    "    # \n",
    "    \"Slip Out\", \"Annoying\", \"Change Position\", \"Too tight\", \"Itchiness\",\n",
    "    \"Soreness\", \"Take off hearing aids\", \"Painful\",\n",
    "\n",
    "    # Target variable\n",
    "    \"Average comfort score\", \"Satisfaction\"\n",
    "]\n",
    "\n",
    "df = df[selected_columns].copy()\n",
    "\n",
    "\n",
    "target_comfort = df[\"Average comfort score\"]\n",
    "# target_satisfaction = df[\"Satisfaction\"]\n",
    "# df = df.drop(columns=[\"Average comfort score\", \"Satisfaction\"])\n",
    "\n",
    "# Satisfaction Classification\n",
    "def map_satisfaction(score):\n",
    "    if score <= 2:\n",
    "        return \"Dissatisfied\"\n",
    "    elif score == 3:\n",
    "        return \"Neutral\"\n",
    "    else:  # 4 or 5\n",
    "        return \"Satisfied\"\n",
    "\n",
    "\n",
    "df[\"satisfaction_class\"] = df[\"Satisfaction\"].apply(map_satisfaction)\n",
    "le = LabelEncoder()\n",
    "y_satisfaction_class = le.fit_transform(df[\"satisfaction_class\"])\n",
    "\n",
    "df = df.drop(columns=[\"Average comfort score\", \"Satisfaction\", \"satisfaction_class\"])\n",
    "\n",
    "\n",
    "# Clean Earpiece Configuration \n",
    "def simplify_config(val):\n",
    "    val = str(val).lower()\n",
    "    if \"dome\" in val and \"custom\" in val:\n",
    "        return \"Custom/Dome\"\n",
    "    elif \"custom\" in val:\n",
    "        return \"Custom\"\n",
    "    elif \"dome\" in val:\n",
    "        return \"Domes\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df[\"Earpiece Configuration\"] = df[\"Earpiece Configuration\"].apply(simplify_config)\n",
    "\n",
    "# One hot encoded\n",
    "categorical_cols = [\n",
    "    \"Style\", \"Platform\", \"Earpiece Configuration\", \"What is your gender?\",\n",
    "    \"What is your current age?\", \"How long have you been using hearing aids?\",\n",
    "    \"sentiment_label\", \"normalized_label\"\n",
    "]\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "X = df_encoded.fillna(0)  \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Comfort Regression Model\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_scaled, target_comfort, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "def build_mlp(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(), metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model_c = build_mlp(X_train_c.shape[1])\n",
    "model_c.fit(X_train_c, y_train_c, epochs=10, batch_size=32, verbose=1)\n",
    "pred_c = model_c.predict(X_test_c).flatten()\n",
    "\n",
    "print(\"\\nComfort Model:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test_c, pred_c))\n",
    "print(\"RÂ²:\", r2_score(y_test_c, pred_c))\n",
    "\n",
    "# Satisfaction Clssifiacation Model\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
    "    X_scaled, y_satisfaction_class, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "def build_classification_mlp(input_dim, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_s = build_classification_mlp(X_train_s.shape[1], num_classes=3)\n",
    "model_s.fit(\n",
    "    X_train_s, y_train_s,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    class_weight=class_weight_dict \n",
    ")\n",
    "\n",
    "\n",
    "pred_probs = model_s.predict(X_test_s)\n",
    "pred_classes = np.argmax(pred_probs, axis=1)\n",
    "\n",
    "print(\"\\nSatisfaction Classification Report:\")\n",
    "print(classification_report(y_test_s, pred_classes, target_names=le.classes_))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test_s, pred_classes), annot=True, fmt='d',\n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Satisfaction Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fca7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Comfort MLP Model\n",
    "# Check the most important 10 features \n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scikeras.wrappers import KerasRegressor  \n",
    "\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(X_train_c.shape[1],)), \n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "wrapped_model = KerasRegressor(model=build_model, epochs=5, batch_size=32, verbose=0)\n",
    "wrapped_model.fit(X_train_c, y_train_c)\n",
    "result = permutation_importance(\n",
    "    wrapped_model, X_test_c, y_test_c,\n",
    "    n_repeats=5, scoring='r2', random_state=42\n",
    ")\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': df_encoded.columns,\n",
    "    'importance_mean': result.importances_mean,\n",
    "    'importance_std': result.importances_std\n",
    "}).sort_values(by=\"importance_mean\", ascending=False)\n",
    "\n",
    "print(importance_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0349b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP For Comfort Model\n",
    "import shap\n",
    "\n",
    "X_sample = pd.DataFrame(X_test_c[:1000], columns=df_encoded.columns)\n",
    "\n",
    "explainer = shap.Explainer(model_c, X_sample)\n",
    "shap_values = explainer(X_sample)\n",
    "\n",
    "shap.plots.bar(shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b0fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP For Comfort Model\n",
    "import pandas as pd\n",
    "\n",
    "X_sample = pd.DataFrame(X_test_c[:1000], columns=df_encoded.columns)\n",
    "explainer = shap.Explainer(model_c, X_sample)\n",
    "shap_values = explainer(X_sample)\n",
    "\n",
    "shap.plots.beeswarm(shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa195de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for check\n",
    "df_plot = pd.read_csv(\"final_model_dataset.csv\")\n",
    "\n",
    "sns.boxplot(x=df_plot['Slip Out'], y=df_plot['Average comfort score'])\n",
    "plt.title(\"Comfort Score vs Slip Out\")\n",
    "plt.xlabel(\"Slip Out (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Comfort Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f46d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP For Comfort Model - 2\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_sample = pd.DataFrame(X_test_c[:100], columns=df_encoded.columns)\n",
    "explainer = shap.Explainer(model_c, X_sample)\n",
    "shap_values = explainer(X_sample)\n",
    "\n",
    "mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "top_indices = np.argsort(mean_abs_shap)[::-1][:20]  # Top 20 here \n",
    "\n",
    "top_features = X_sample.columns[top_indices]\n",
    "top_importances = mean_abs_shap[top_indices]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(range(20), top_importances[::-1], color=\"#80cfff\")  \n",
    "plt.yticks(range(20), top_features[::-1])\n",
    "plt.xlabel(\"Mean |SHAP value|\")\n",
    "plt.title(\"Top 20 SHAP Feature Importances (Comfort Model)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbc9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satisfaction Model Shapley Additive Explanations - satisfied\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X_sample_s = pd.DataFrame(X_test_s[:100], columns=df_encoded.columns)\n",
    "\n",
    "explainer_s = shap.Explainer(model_s, X_sample_s)\n",
    "shap_values_s = explainer_s(X_sample_s)\n",
    "\n",
    "class_idx = 2  # \"Satisfied\"\n",
    "mean_abs_shap = np.abs(shap_values_s.values[:, :, class_idx]).mean(axis=0)\n",
    "top_indices = np.argsort(mean_abs_shap)[::-1][:20]\n",
    "\n",
    "top_features = X_sample_s.columns[top_indices]\n",
    "top_importances = mean_abs_shap[top_indices]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(range(20), top_importances[::-1], color=\"#80cfff\")\n",
    "plt.yticks(range(20), top_features[::-1])\n",
    "plt.xlabel(\"Mean |SHAP value|\")\n",
    "plt.title(\"Top 20 SHAP Feature Importances (Satisfaction Class: Satisfied)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b8081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satisfaction MOdel Shapley Additive Explanations - dissatisfied\n",
    "shap.plots.beeswarm(shap_values_s[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5478db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary For Satisfaction\n",
    "shap.plots.bar(shap_values_s[..., 2], max_display=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c0a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary For Dissatisfied\n",
    "shap.plots.bar(shap_values_s[..., 0], max_display=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7101fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dissatisfied\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X_sample_s = pd.DataFrame(X_test_s[:100], columns=df_encoded.columns)\n",
    "\n",
    "explainer_s = shap.Explainer(model_s, X_sample_s)\n",
    "shap_values_s = explainer_s(X_sample_s)\n",
    "\n",
    "class_idx = 0  # Dissatisfied\n",
    "\n",
    "mean_abs_shap = np.abs(shap_values_s.values[:, :, class_idx]).mean(axis=0)\n",
    "top_indices = np.argsort(mean_abs_shap)[::-1][:20]\n",
    "top_features = X_sample_s.columns[top_indices]\n",
    "top_importances = mean_abs_shap[top_indices]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(range(20), top_importances[::-1], color=\"#80cfff\")\n",
    "plt.yticks(range(20), top_features[::-1])\n",
    "plt.xlabel(\"Mean |SHAP value|\")\n",
    "plt.title(\"Top 20 SHAP Feature Importances (Satisfaction Class: Dissatisfied)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satisfied\n",
    "import shap\n",
    "import pandas as pd\n",
    "\n",
    "X_sample_s = pd.DataFrame(X_test_s[:100], columns=df_encoded.columns)\n",
    "\n",
    "explainer_s = shap.Explainer(model_s, X_sample_s)\n",
    "shap_values_s = explainer_s(X_sample_s)\n",
    "\n",
    "\n",
    "shap.plots.beeswarm(shap_values_s[..., 2]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for test\n",
    "pivot_table = df_raw.pivot_table(values='Average comfort score',\n",
    "                             index='What is your current age?',\n",
    "                             columns='How long have you been using hearing aids?',\n",
    "                             aggfunc='mean')\n",
    "\n",
    "sns.heatmap(pivot_table, annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n",
    "plt.title(\"Mean Comfort Score by Age & HA Usage Duration\")\n",
    "plt.xlabel(\"HA Usage Duration\")\n",
    "plt.ylabel(\"Age Group\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc99a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Comfort\n",
    "plt.scatter(y_test_c, pred_c, alpha=0.5)\n",
    "plt.xlabel(\"True Comfort Score\")\n",
    "plt.ylabel(\"Predicted Comfort Score\")\n",
    "plt.title(\"Comfort Score: True vs Predicted\")\n",
    "plt.grid(True)\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# Satisfaction\n",
    "plt.scatter(y_test_s, pred_s, alpha=0.5)\n",
    "plt.xlabel(\"True Satisfaction Score\")\n",
    "plt.ylabel(\"Predicted Satisfaction Score\")\n",
    "plt.title(\"Satisfaction Score: True vs Predicted\")\n",
    "plt.grid(True)\n",
    "plt.plot([0, 5], [0, 5], color='red', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f91a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save MLP Model\n",
    "model_c.save(\"mlp_comfort_model.keras\")\n",
    "model_s.save(\"mlp_satisfaction_model.keras\")\n",
    "\n",
    "import joblib\n",
    "joblib.dump(scaler, \"scaler.save\")\n",
    "print(\"Scaler saved as 'scaler.save'\")\n",
    "\n",
    "columns_template = pd.DataFrame(columns=df_encoded.columns)\n",
    "columns_template.to_csv(\"onehot_template.csv\", index=False)\n",
    "print(\"One-hot template saved as 'onehot_template.csv'\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
